---
title: "至少在 2024 年里我对人工智能/AI的一些看法"
---

我不会弄 AI 也没接触太多（在线或者本地的）最终产品，不过也算是了解过一些神经网络相关的知识。\
加上经历了近两年来 AI 的爆火，心里是有些想说的东西的。\
所以就写出来咯，是不太能拿来当参考啦，但这是我现在的看法。

另外，怎么这篇帖子行文这么正经，还是我写的吗？

## 营销上的歧义

诚然，ChatGPT 3 的出现让全世界意识到了人工智能的力量（不过 NVIDIA 其实更早）。OpenAI 的一次又一次模型更新也在告诉全世界，通用人工智能的前景是无限的。\
人们对此感到惊奇，担忧，恐慌，最后明白了现阶段大语言模型的特性后以此为突破点寻找商机。无论是个人还是大型公司都是如此。

你看，人类就是这样的呀，懂得变通，去做对自己最有利的事情。但现阶段的“人工智能”不行，至少那些被称为“大语言模型”的东西不行。\
除非有些具有里程碑意义的硬件或者算法出现来完全模拟人类有创造力的思考方式，那人工智能永远都比不上人类的智能，它们仍然保留了来自计算机的专科与死板，并拙劣的拼凑/模仿着人类的文字和其中蕴藏的情绪。\
不过这里也有些营销上的问题存在。

当今的“人工智能”并不是 GLaDOS 它们没有人类般的智慧，但恰恰好的介于二者之间。\
人们用它的能力训练了了一套又一套的普通算法难以实现的逻辑，但远远达不到人类的智能。\
或许它们在以前更通用的代称叫“机器学习/神经网络”吧？\
我还是会更喜欢这些更准确的名字。

## 最终产品上的问题

所有公司都想给自己的产品加上人工智能的标签，但成果很显然不尽如人意。\
当所有公司都开始关心产品有没有 AI 这个标签，而把用户体验放到第二位时，我们或许也该认识到这场新时代的金融泡沫发展到了哪种地步了。

最终受益的除了以 NVIDIA 为首的大公司们又还有谁呢。

## 对于普通人来说AI的用处

但，大语言模型真的没用吗？\
在推广新技术的层面上，人工智能的热潮明显没有起到什么作用，甚至起到了些许副作用。但这问题不大，毕竟从人类整体来看其实挺合理的。\
但对于会使用 AI 的人来说，它们可以变为一个优秀的参考和辅助工具。\
美术可以参考图像模型的初稿寻找灵感；编辑/作家可以用语言模型润色和构思自己的文章；程序员是离模型最近的一个群体，在代码分析和预测上 AI 也能很好的提升工作效率。

在这个过程中，一个重要的因素在于工具。\
不是所有人都会或者有心思部署那些 AI 软件甚至明白底层框架。使用者应该用更简单的方式来访问这些工具。\
但同时这些工具本身也应该给用户提供足够多的创作空间，只有将主动权交给人类用户才能最大程度的结合神经网络与人类的创造力。

## 对于学习新东西

ChatGPT 3 的出现让这些模型看着更加类人，但在我看来努力利用它们的优势让它们为自己所用，会比把需求直接丢进去并抱以期待更有意义。

大语言模型的输出永远是不可靠的，其实就像一个人的输出也不可靠一样。想要得到最真实的信息是必然要尽量减少与信息源之间的层数的。\
想要得到最真实可靠的信息，唯一的办法就是锻炼自己的搜索能力。\
但也就像大多数人夸奖的那样，能联网的语言模型有能力搜索和总结大多数常见的信息并加以总结并在几分钟内让用户满意，这相比于绝对的准确来说也是很有竞争力的。

有点想到了手机领域里有线耳机和无线耳机的换代233。说不定未来这段历史真的会重新上演一次呢。不过以此引出的危机还是先等到以后再说吧。

不过在现在人也可以和 AI 共处呀，修缮用户的资料或者只是提供一个简洁详尽的介绍，这些场景都是在提升用户。\
提升自己的能力与使用 AI 并不冲突，甚至相辅相成。

## 训练模型时的版权问题

这里的看法大概会更片面一点吧，但这是是我的看法。

首先，如果模型是由一家公司训练出来的，并且他们已经拥有了训练数据的版权，那从任何角度看似乎都没什么问题。\
这是一定要搞清楚的，虽说作为用户我们永远也不知道这些数据背后的版权状态。

那，对于无版权数据呢？\
我不懂法律但用侵权的数据拿来卖钱或者直接公开都是不符合版权法的规定的，这是钉死的事。

但从 AI 的角度想，虽然现在的 AI 比不上人类，但它们就是一份人类大脑的粗糙仿制品。如果说它们的工作就是拼凑字符或者复制粘贴图像块，那人类又是什么呢。\
虽然现在的 AI 在自我创造上做的还不够，但对于未来或甚至现在的顶级模型来说，这件事应该已经值得去思考了吧。

我对于版权纠纷上的未来想不太远，不过说不定在未来人们会因此引发某些大规模运动呢。\
未来会很好玩的... 应该吧。

## EOF

对于未来与现在，我应该都会保持中性且尊重的态度对待各种神经网络的应用。毕竟技术是就中性的，有偏向的只有人类。\
但提到高级 AI 的过度智能或者失控的风险，我心里好像也没有多少底。\
所以，以后我大概率也会尝试更深入的了解它们吧，但那要等到我的数学和其他技术栈过关了再说。
